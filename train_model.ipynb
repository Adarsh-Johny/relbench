{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyg_lib\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"pyg-lib Version:\", pyg_lib.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNziUzq9nTdU",
    "outputId": "edb40abf-b984-4fec-8033-1ed92fbdb128"
   },
   "outputs": [],
   "source": [
    "# # # Install required packages.\n",
    "# !pip install torch==2.6.0\n",
    "# !pip install torch-geometric torch-sparse torch-scatter torch-cluster torch-spline-conv pyg-lib -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
    "# !pip install pytorch_frame\n",
    "# !pip install -U sentence-transformers # we need another package for text encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:05:04.397024Z",
     "iopub.status.busy": "2024-07-26T00:05:04.396612Z",
     "iopub.status.idle": "2024-07-26T00:05:05.049064Z",
     "shell.execute_reply": "2024-07-26T00:05:05.048407Z",
     "shell.execute_reply.started": "2024-07-26T00:05:04.397003Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "import torch_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DWB-Kf6nl2y"
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "\n",
    "dataset = get_dataset(\"rel-f1\", download=True)\n",
    "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
    "\n",
    "train_table = task.get_table(\"train\")\n",
    "val_table = task.get_table(\"val\")\n",
    "test_table = task.get_table(\"test\")\n",
    "\n",
    "out_channels = 1\n",
    "loss_fn = L1Loss()\n",
    "tune_metric = \"rmse\"\n",
    "higher_is_better = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKFT5H51j_Um"
   },
   "source": [
    "Let's check out the training table just to make sure it looks fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABN_fdN3kAB9",
    "outputId": "03d4a31a-124d-45c7-b4dc-9713e5e4b942"
   },
   "outputs": [],
   "source": [
    "train_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQhuHIdHkOxv"
   },
   "source": [
    "Note that to load the data we did not require any deep learning libraries. Now we introduce the PyTorch Frame library, which is useful for encoding individual tables into initial node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNzfdwsrkPIo",
    "outputId": "c985185e-b785-405e-bd46-ebf2f48e3ac6"
   },
   "outputs": [],
   "source": [
    "# Some book keeping\n",
    "from torch_geometric.seed import seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  # check that it's cuda if you want it to run in reasonable time!\n",
    "root_dir = \".tutorials/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Y79g5H0kVjX"
   },
   "source": [
    "The first big move is to build a graph out of the database. Here we use our pre-prepared conversion function.\n",
    "\n",
    "The source code can be found at: https://github.com/snap-stanford/relbench/blob/main/relbench/modeling/graph.py\n",
    "\n",
    "Each node in the graph corresonds to a single row in the database. Crucially, PyTorch Frame stores whole tables as objects in a way that is compatibile with PyG minibatch sampling, meaning we can sample subgraphs as in https://arxiv.org/abs/1706.02216, and retrieve the relevant raw features.\n",
    "\n",
    "PyTorch Frame also stores the `stype` (i.e., modality) of each column, and any specialized feature encoders (e.g., text encoders) to be used later. So we need to configure the `stype` for each column, for which we use a function that tries to automatically detect the `stype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kiV3TGI-kRuy",
    "outputId": "98e88ec3-ab38-4a14-8dd8-24f3ea349893"
   },
   "outputs": [],
   "source": [
    "from relbench.modeling.utils import get_stype_proposal\n",
    "\n",
    "db = dataset.get_db()\n",
    "col_to_stype_dict = get_stype_proposal(db)\n",
    "col_to_stype_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sm3uYXqXkbZt"
   },
   "source": [
    "If trying a new dataset, you should definitely check through this dict of `stype`s to check that look right, and manually change any mistakes by the auto-detection function.\n",
    "\n",
    "Next we also define our text encoding model, which we use GloVe embeddings for speed and convenience. Feel free to try alternatives here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQHYmgIxkX1j",
    "outputId": "857b70dd-e7eb-4b09-a5cd-394fccef758a"
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class GloveTextEmbedding:\n",
    "    def __init__(self, device: Optional[torch.device\n",
    "                                       ] = None):\n",
    "        self.model = SentenceTransformer(\n",
    "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def __call__(self, sentences: List[str]) -> Tensor:\n",
    "        return torch.from_numpy(self.model.encode(sentences))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-BBpUrakdwY",
    "outputId": "b152bf13-f47d-4728-d58b-fc65f738b03d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "output_file = 'output_fi.pkl'\n",
    "\n",
    "if os.path.exists(output_file):\n",
    "    # File exists: load the data\n",
    "    with open(output_file, 'rb') as f:\n",
    "        data, col_stats_dict = pickle.load(f)\n",
    "    print(\"Loaded data from file.\")\n",
    "else:\n",
    "    # File does not exist: run the code and save the output\n",
    "    from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "    from relbench.modeling.graph import make_snapshot_graph\n",
    "    # Ensure GloveTextEmbedding, device, db, col_to_stype_dict, and root_dir are defined\n",
    "    text_embedder_cfg = TextEmbedderConfig(\n",
    "        text_embedder=GloveTextEmbedding(device=device), batch_size=256\n",
    "    )\n",
    "    \n",
    "    data, col_stats_dict = make_snapshot_graph(\n",
    "        db,\n",
    "        col_to_stype_dict=col_to_stype_dict,              # specified column types\n",
    "        main_table_name=\"races\",                          # use 'races' table as timestamp reference\n",
    "        interval_days=30,                                 # generate snapshots every 30 days\n",
    "        text_embedder_cfg=text_embedder_cfg,              # chosen text encoder\n",
    "        cache_dir=os.path.join(root_dir, \"rel-f1_materialized_cache\"),  # store materialized graph for convenience\n",
    "    )\n",
    "    \n",
    "    # Save the output to a file for future use\n",
    "    with open(output_file, 'wb') as f:\n",
    "        pickle.dump((data, col_stats_dict), f)\n",
    "    print(\"Data computed and saved to file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "def visualize_hetero_graph(snapshot, num_nodes=10):\n",
    "    \"\"\"Visualize a small portion of a heterogeneous graph with a specific edge type.\"\"\"\n",
    "    \n",
    "    # Select the first available edge type (e.g., ('node_type1', 'relation', 'node_type2'))\n",
    "    edge_type = list(snapshot.edge_index_dict.keys())[0]\n",
    "    print(f\"Using edge type: {edge_type}\")  # Debugging\n",
    "\n",
    "    # Extract edge index for the selected edge type\n",
    "    edge_index = snapshot[edge_type].edge_index\n",
    "    \n",
    "    # Convert the selected subgraph to NetworkX\n",
    "    nx_graph = nx.Graph()  # Create an empty NetworkX graph\n",
    "\n",
    "    # Add edges from edge_index\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        src = int(edge_index[0, i].item())\n",
    "        dst = int(edge_index[1, i].item())\n",
    "        nx_graph.add_edge(src, dst)  # Add edge to the NetworkX graph\n",
    "\n",
    "    # Get a subset of nodes\n",
    "    sampled_nodes = list(nx_graph.nodes)[:num_nodes]\n",
    "    subgraph = nx_graph.subgraph(sampled_nodes)\n",
    "    \n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    nx.draw(subgraph, with_labels=True, node_color='lightblue', edge_color='gray', node_size=500, font_size=10)\n",
    "    plt.title(f\"Visualization of {num_nodes} nodes from edge type {edge_type}\")\n",
    "    plt.show()\n",
    "\n",
    "# Select the first snapshot\n",
    "snapshot = data[16]  # Assuming data is a list of snapshots\n",
    "\n",
    "# Call the function\n",
    "visualize_hetero_graph(snapshot, num_nodes=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwQejmg0kzOg"
   },
   "source": [
    "We can now check out `data`, our main graph object. `data` is a heterogeneous and temporal graph, with node types given by the table it originates from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gt4a8lw1kufy",
    "outputId": "4117959f-6f0d-4c31-9489-49db7d5f3c5d"
   },
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yd6DqCXgk41x"
   },
   "source": [
    "We can also check out the TensorFrame for one table like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mMQTQeLk1rl",
    "outputId": "04d698af-a4f4-4a98-8321-b5f8dc6ee10d"
   },
   "outputs": [],
   "source": [
    "col_stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kbysKXMk-3X"
   },
   "source": [
    "This may be a little confusing at first, as in graph ML it is more standard to associate to the graph object `data` a tensor, e.g., `data.x` for which `data.x[idx]` is a 1D array/tensor storing all the features for node with index `idx`.\n",
    "\n",
    "But actually this `data` object behaves similarly. For a given node type, e.g., `races` again, `data['races']` stores two pieces of information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDIcp7L5k6pU",
    "outputId": "be742ecb-02db-43e6-9c12-53fb00e51fec"
   },
   "outputs": [],
   "source": [
    "print(len(data))  # Number of snapshots created\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z18qPRPllB1H"
   },
   "source": [
    "A `TensorFrame` object, and a timestamp for each node. The `TensorFrame` object acts analogously to the usual tensor of node features, and you can simply use indexing to retrieve the features of a single row (node), or group of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYZ28pzNlG4s",
    "outputId": "1066a167-2e3b-4ad6-d929-02acf18cad0e"
   },
   "outputs": [],
   "source": [
    "data[1][\"races\"].tf[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ql15svcelK3A"
   },
   "source": [
    "We can also check the edge indices between two different node types, such as `races` amd `circuits`. Note that the edges are also heterogenous, so we also need to specify which edge type we want to look at. Here we look at `f2p_curcuitId`, which are the directed edges pointing _from_ a race (the `f` stands for `foreign key`), _to_ the circuit at which te race happened (the `p` stands for `primary key`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.__sizeof__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_type in data[0].edge_types:\n",
    "    print(f\"Edge: {edge_type}, Shape: {data[0][edge_type].edge_index.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_type in data[14].node_types:\n",
    "    print(f\"Node: {node_type}, Feature Shape: {data[14][node_type].tf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TynkD36QlInL",
    "outputId": "abc2f80d-5ff4-42b1-f9e3-bd9f004d84ee"
   },
   "outputs": [],
   "source": [
    "data[1][(\"races\", \"f2p_circuitId\", \"circuits\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx4V5KCelNxl"
   },
   "source": [
    "Now we are ready to instantiate our data loaders. For this we will need to import PyTorch Geometric, our GNN library. Whilst we're at it let's add a seed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUHVG-g6lM-b"
   },
   "outputs": [],
   "source": [
    "from relbench.modeling.graph import get_node_train_table_input\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "loader_dict = {}\n",
    "\n",
    "if not data:\n",
    "    raise ValueError(\"No snapshots found in `data`. Ensure make_snapshot_graph() returns a non-empty list.\")\n",
    "\n",
    "for split, table in [\n",
    "    (\"train\", train_table),\n",
    "    (\"val\", val_table),\n",
    "    (\"test\", test_table),\n",
    "]:\n",
    "    table_input = get_node_train_table_input(\n",
    "        table=table,\n",
    "        task=task,\n",
    "    )\n",
    "    entity_table = table_input.nodes[0]  # âœ… Get the main node type for training\n",
    "\n",
    "    loader_dict[split] = []\n",
    "for snapshot in data:  # âœ… Iterate over snapshots\n",
    "    # âœ… Ensure time_attr is set if input_time exists\n",
    "    time_attr = \"time\" if table_input.time is not None and \"time\" in snapshot.get(entity_table, {}) else None\n",
    "\n",
    "    # ðŸ”¥ Check if entity_table exists in snapshot\n",
    "    print(f\"Available node types in snapshot[0]: {snapshot.node_types}\")\n",
    "    if entity_table not in snapshot.node_types:\n",
    "        print(f\"âš ï¸ Warning: {entity_table} not found in snapshot. Skipping this snapshot.\")\n",
    "        continue  # Skip this snapshot\n",
    "\n",
    "    # ðŸ”¥ Check if num_nodes is valid\n",
    "    if snapshot[entity_table].num_nodes is None:\n",
    "        print(f\"âš ï¸ Warning: {entity_table} has no valid nodes in snapshot. Skipping this snapshot.\")\n",
    "        continue  # Skip this snapshot\n",
    "\n",
    "    loader = NeighborLoader(\n",
    "        snapshot,  # âœ… Use snapshot instead of a single data graph\n",
    "        num_neighbors=[10, 10],  # âœ… Adjust depth if needed\n",
    "        time_attr=time_attr,  # âœ… Ensure \"time\" exists for entity_table\n",
    "        input_nodes=(entity_table, None),  # âœ… Use tuple format (node_type, indices)\n",
    "        input_time=table_input.time if time_attr is not None else None,  # âœ… Fix input_time conflict\n",
    "        transform=table_input.transform,\n",
    "        batch_size=512,\n",
    "        temporal_strategy=\"uniform\",\n",
    "        shuffle=(split == \"train\"),\n",
    "        num_workers=0,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "\n",
    "    loader_dict[split].append(loader)\n",
    "\n",
    "\n",
    "for snapshot_loader in loader_dict[\"train\"]:\n",
    "    for batch in snapshot_loader:\n",
    "        print(batch)  # Process each batch per snapshot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Available node types in snapshot[0]: {data[0].node_types}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQc8BWsGludR"
   },
   "source": [
    "Now we need our model...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3m3jEqClQnw"
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import BCEWithLogitsLoss, Embedding, ModuleDict\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_frame.data.stats import StatType\n",
    "from torch_geometric.typing import NodeType\n",
    "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
    "\n",
    "# âœ… LSTM-Based Temporal Encoder for Evolving Node Embeddings\n",
    "class LSTMBasedTemporalEncoder(torch.nn.Module):\n",
    "    def __init__(self, node_types, channels):\n",
    "        super().__init__()\n",
    "        self.lstm_dict = torch.nn.ModuleDict({\n",
    "            node_type: torch.nn.LSTM(input_size=channels, hidden_size=channels, batch_first=True)\n",
    "            for node_type in node_types\n",
    "        })\n",
    "\n",
    "    def forward(self, h_dict, time_dict, batch_dict):\n",
    "        updated_h_dict = {}\n",
    "        for node_type, lstm in self.lstm_dict.items():\n",
    "            if node_type in h_dict and h_dict[node_type].size(0) > 0:  # âœ… Skip empty inputs\n",
    "                h, _ = lstm(h_dict[node_type].unsqueeze(0))  # Apply LSTM\n",
    "                updated_h_dict[node_type] = h.squeeze(0)\n",
    "            else:\n",
    "                updated_h_dict[node_type] = h_dict.get(node_type, torch.zeros(0))  # âœ… Keep existing values\n",
    "        return updated_h_dict\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: List[HeteroData],\n",
    "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
    "        num_layers: int,\n",
    "        channels: int,\n",
    "        out_channels: int,\n",
    "        aggr: str,\n",
    "        norm: str,\n",
    "        shallow_list: List[NodeType] = [],\n",
    "        id_awareness: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = HeteroEncoder(\n",
    "            channels=channels,\n",
    "            node_to_col_names_dict={\n",
    "                node_type: data[0][node_type].tf.col_names_dict  # âœ… Use the first snapshot\n",
    "                for node_type in data[0].node_types\n",
    "            },\n",
    "            node_to_col_stats=col_stats_dict,\n",
    "        )\n",
    "        \n",
    "        self.temporal_encoder = HeteroTemporalEncoder(\n",
    "            node_types=[\n",
    "                node_type for node_type in data[0].node_types if \"time\" in data[0][node_type]\n",
    "            ],\n",
    "            channels=channels,\n",
    "        )\n",
    "\n",
    "        self.gnn = HeteroGraphSAGE(\n",
    "            node_types=data[0].node_types,  # âœ… Use the first snapshot to extract node types\n",
    "            edge_types=data[0].edge_types,\n",
    "            channels=channels,\n",
    "            aggr=aggr,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "\n",
    "        self.head = MLP(\n",
    "            channels,\n",
    "            out_channels=out_channels,\n",
    "            norm=norm,\n",
    "            num_layers=1,\n",
    "        )\n",
    "\n",
    "        self.embedding_dict = ModuleDict(\n",
    "            {\n",
    "                node: Embedding(data[0].num_nodes_dict.get(node, 0), channels)\n",
    "                for node in shallow_list if data[0].num_nodes_dict.get(node, 0) > 0\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.id_awareness_emb = None\n",
    "        if id_awareness:\n",
    "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.encoder.reset_parameters()\n",
    "        self.temporal_encoder.reset_parameters()\n",
    "        self.gnn.reset_parameters()\n",
    "        self.head.reset_parameters()\n",
    "        for embedding in self.embedding_dict.values():\n",
    "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
    "        if self.id_awareness_emb is not None:\n",
    "            self.id_awareness_emb.reset_parameters()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch: HeteroData,\n",
    "        entity_table: NodeType,\n",
    "    ) -> Tensor:\n",
    "        seed_time = batch.time_dict.get(entity_table, None)\n",
    "\n",
    "        x_dict = self.encoder({node_type: batch[node_type].tf for node_type in batch.node_types})\n",
    "\n",
    "        if seed_time is None:\n",
    "            print(f\"âš ï¸ Warning: `{entity_table}` missing time information.\")\n",
    "            rel_time_dict = {}\n",
    "        else:\n",
    "            rel_time_dict = self.temporal_encoder(seed_time, batch.time_dict, batch.batch_dict)\n",
    "\n",
    "        for node_type, rel_time in rel_time_dict.items():\n",
    "            x_dict[node_type] += rel_time\n",
    "\n",
    "        for node_type, embedding in self.embedding_dict.items():\n",
    "            x_dict[node_type] += embedding(batch[node_type].n_id)\n",
    "\n",
    "        x_dict = self.gnn(x_dict, batch.edge_index_dict)\n",
    "\n",
    "        return self.head(x_dict[entity_table][: seed_time.size(0)])\n",
    "\n",
    "\n",
    "model = Model(\n",
    "    data=data,\n",
    "    col_stats_dict=col_stats_dict,\n",
    "    num_layers=2,\n",
    "    channels=128,\n",
    "    out_channels=1,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    "    id_awareness=True,  # Enable ID awareness\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_fn = BCEWithLogitsLoss()\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl-6So7Llb-p"
   },
   "source": [
    "We also need standard train/test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAHRIr15lVs6"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def train() -> float:\n",
    "    model.train()\n",
    "\n",
    "    loss_accum = count_accum = 0\n",
    "    for snapshot_loader in tqdm(loader_dict[\"train\"]):  # âœ… Iterate over snapshot loaders\n",
    "        for batch in snapshot_loader:  # âœ… Iterate over batches\n",
    "            batch = batch.to(device)  # âœ… Now applies correctly to `HeteroData`\n",
    "\n",
    "\n",
    "        if task.entity_table not in batch:\n",
    "            print(f\"âš ï¸ Warning: `{task.entity_table}` missing in batch. Skipping.\")\n",
    "            continue  # Skip invalid batches\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch, task.entity_table)\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "\n",
    "        loss = loss_fn(pred.float(), batch[task.entity_table].y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_accum += loss.detach().item() * pred.size(0)\n",
    "        count_accum += pred.size(0)\n",
    "\n",
    "    return loss_accum / count_accum if count_accum > 0 else float(\"inf\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    for snapshot_loader in loader:  # âœ… Iterate over snapshot loaders\n",
    "        for batch in snapshot_loader:  # âœ… Iterate over batches\n",
    "            batch = batch.to(device)  # âœ… Now applies correctly to `HeteroData`\n",
    "\n",
    "            pred = model(batch, task.entity_table)\n",
    "            pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "            pred_list.append(pred.detach().cpu())\n",
    "    return torch.cat(pred_list, dim=0).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s-p7dW1ledd"
   },
   "source": [
    "Now we are ready to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yF3W68Eqlew_",
    "outputId": "a81a48dc-234a-47f3-8759-8dc9a766661c"
   },
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train()\n",
    "    val_pred = test(loader_dict[\"val\"])\n",
    "    print(f\"Epoch: {epoch+1}, Train loss: {train_loss}\")\n",
    "\n",
    "# Test Model\n",
    "test_pred = test(loader_dict[\"test\"])\n",
    "print(f\"Test predictions: {test_pred}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pyg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
